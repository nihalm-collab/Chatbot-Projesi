# app.py

import os
from dotenv import load_dotenv
import streamlit as st
from datasets import load_dataset
from langchain.vectorstores import Chroma
from langchain.chat_models import ChatOpenAI
from langchain.embeddings import OpenAIEmbeddings
from langchain.chains import ConversationalRetrievalChain

# --------------------------
# 1ï¸âƒ£ .env DosyasÄ±nÄ± YÃ¼kle
# --------------------------
load_dotenv()  # .env dosyasÄ±ndaki deÄŸiÅŸkenleri alÄ±r

HF_TOKEN = os.getenv("HUGGINGFACE_TOKEN")
GEMINI_KEY = os.getenv("GEMINI_API_KEY")

if not HF_TOKEN:
    st.error("Huggingface token bulunamadÄ±! LÃ¼tfen .env dosyasÄ±na ekleyin.")
    st.stop()
if not GEMINI_KEY:
    st.error("Gemini API key bulunamadÄ±! LÃ¼tfen .env dosyasÄ±na ekleyin.")
    st.stop()

os.environ["OPENAI_API_KEY"] = GEMINI_KEY  # Gemini API key olarak geÃ§er

# --------------------------
# 2ï¸âƒ£ Streamlit BaÅŸlÄ±ÄŸÄ±
# --------------------------
st.set_page_config(page_title="Kitap AsistanÄ± Chatbot", page_icon="ğŸ“š")
st.title("ğŸ“š Kitap AsistanÄ± Chatbot (.env Destekli)")

# --------------------------
# 3ï¸âƒ£ Veri Seti YÃ¼kleme
# --------------------------
@st.cache_data
def load_data():
    dataset = load_dataset("alibayram/kitapyurdu_yorumlar", use_auth_token=HF_TOKEN)
    df = dataset['train'].to_pandas().head(500)  # hÄ±zlÄ± prototip
    return df

df = load_data()
st.write("Veri setinden Ã¶rnek yorumlar:", df.head(3))

# --------------------------
# 4ï¸âƒ£ Embedding ve VektÃ¶r Database
# --------------------------
@st.cache_resource
def create_vectorstore(df):
    embeddings = OpenAIEmbeddings()
    vectordb = Chroma.from_texts(df['yorum'].tolist(), embedding=embeddings)
    return vectordb

vectordb = create_vectorstore(df)

# --------------------------
# 5ï¸âƒ£ RAG Pipeline
# --------------------------
@st.cache_resource
def create_rag_chain(vectordb):
    llm = ChatOpenAI(temperature=0)  # Gemini API key kullanÄ±yor
    chain = ConversationalRetrievalChain.from_llm(
        llm=llm,
        retriever=vectordb.as_retriever()
    )
    return chain

rag_chain = create_rag_chain(vectordb)

# --------------------------
# 6ï¸âƒ£ Chat ArayÃ¼zÃ¼
# --------------------------
if 'chat_history' not in st.session_state:
    st.session_state['chat_history'] = []

user_input = st.text_input("Sorunuzu buraya yazÄ±n:")

if user_input:
    with st.spinner("Cevap oluÅŸturuluyor..."):
        result = rag_chain({"question": user_input, "chat_history": st.session_state['chat_history']})
        answer = result['answer']
        st.session_state['chat_history'].append((user_input, answer))
        st.write("**Cevap:**", answer)

# --------------------------
# 7ï¸âƒ£ Sohbet GeÃ§miÅŸi
# --------------------------
if st.session_state['chat_history']:
    st.write("### Sohbet GeÃ§miÅŸi")
    for i, (q, a) in enumerate(st.session_state['chat_history']):
        st.markdown(f"**Soru {i+1}:** {q}")
        st.markdown(f"**Cevap {i+1}:** {a}")
        st.write("---")

# --------------------------
# 8ï¸âƒ£ Ã‡alÄ±ÅŸtÄ±rma TalimatÄ±
# --------------------------
st.write("ğŸ’¡ Kodun Ã§alÄ±ÅŸmasÄ± iÃ§in terminalde ÅŸu komut kullanÄ±labilir:")
st.code("streamlit run app.py")
